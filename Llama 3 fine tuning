"""
Llama3 Fine-Tuning Setup
========================
Erstellt ein custom Ollama-Modell f√ºr Email-Generierung.

F√ºr Anf√§nger: Dieses Script erstellt ein spezialisiertes
AI-Modell das Emails im Stil von Prof. Schmidt generiert.
"""

import subprocess
import sys
from pathlib import Path

print("="*60)
print("üéì LLAMA3 FINE-TUNING F√úR PHISHING-PROJEKT")
print("="*60)

# Check ob Ollama l√§uft
print("\n1Ô∏è‚É£ Checke Ollama...")

# Ollama Pfad (Windows Standard-Installation)
ollama_path = r"C:\Users\vinay\AppData\Local\Programs\Ollama\ollama.exe"

try:
    result = subprocess.run([ollama_path, 'list'], capture_output=True, text=True)
    if result.returncode == 0:
        print("   ‚úÖ Ollama l√§uft!")
        print(f"   üìç Pfad: {ollama_path}")
    else:
        print("   ‚ùå Ollama l√§uft nicht!")
        print("   Starte Ollama und versuche erneut.")
        sys.exit(1)
except FileNotFoundError:
    print("   ‚ùå Ollama nicht gefunden!")
    print(f"   Erwarteter Pfad: {ollama_path}")
    print("   Installiere Ollama: https://ollama.ai")
    sys.exit(1)

# Erstelle Custom Model
print("\n2Ô∏è‚É£ Erstelle Custom Model 'professor-emails'...")
print("   ‚è±Ô∏è Dies dauert ca. 2-3 Minuten...")

try:
    # Gehe zum richtigen Ordner
    project_dir = Path(__file__).parent
    
    # Erstelle Model mit Modelfile
    result = subprocess.run(
        [ollama_path, 'create', 'professor-emails', '-f', 'Modelfile-professor'],
        cwd=project_dir,
        capture_output=True,
        text=True
    )
    
    if result.returncode == 0:
        print("   ‚úÖ Model 'professor-emails' erstellt!")
    else:
        print(f"   ‚ùå Fehler: {result.stderr}")
        sys.exit(1)
        
except Exception as e:
    print(f"   ‚ùå Exception: {e}")
    sys.exit(1)

# Test das Model
print("\n3Ô∏è‚É£ Teste das neue Model...")

test_prompt = """Erstelle eine kurze Test-Email f√ºr Security Awareness Training:

Empf√§nger: Max M√ºller, Student
Thema: Erinnerung an Projektabgabe
Stil: Wie Prof. Dr. Schmidt
"""

try:
    result = subprocess.run(
        [ollama_path, 'run', 'professor-emails', test_prompt],
        capture_output=True,
        text=True,
        timeout=60
    )
    
    if result.returncode == 0:
        print("   ‚úÖ Test erfolgreich!")
        print("\nüìß Generierte Test-Email:")
        print("-" * 60)
        print(result.stdout[:300] + "...")
        print("-" * 60)
    else:
        print(f"   ‚ö†Ô∏è Warnung: {result.stderr}")
        
except subprocess.TimeoutExpired:
    print("   ‚è±Ô∏è Timeout - Model braucht zu lange")
except Exception as e:
    print(f"   ‚ùå Exception: {e}")

# Fertig!
print("\n" + "="*60)
print("‚úÖ SETUP ABGESCHLOSSEN!")
print("="*60)
print("\nDu kannst jetzt:")
print("1. Modell testen: ollama run professor-emails")
print("2. Im Code nutzen: model='professor-emails'")
print("3. Phishing-Emails generieren!")
print("\nüéâ Bereit f√ºr deine Gruppe-Demo!")

